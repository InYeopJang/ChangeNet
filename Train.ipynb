{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "#### References\n",
    "* https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "* https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.3.0\n",
      "Device: cuda:0\n",
      "Number of GPUs Available: 8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import models\n",
    "import losses\n",
    "import utils_train\n",
    "import change_dataset_np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "import helper_augmentations\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "num_classes = 2\n",
    "batch_size = 20\n",
    "img_size = 224\n",
    "base_lr = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "num_gpu = torch.cuda.device_count()\n",
    "batch_size *= num_gpu\n",
    "base_lr *= num_gpu\n",
    "print('Number of GPUs Available:', num_gpu)\n",
    "\n",
    "train_pickle_file = './proc_dataset/change_dataset_train.pkl'\n",
    "val_pickle_file = './proc_dataset/change_dataset_train.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(img_size),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        #helper_augmentations.SwapReferenceTest(),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0, hue=0),\n",
    "        #helper_augmentations.JitterGamma(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "train_dataset = change_dataset_np.ChangeDatasetNumpy(train_pickle_file, data_transforms['train'])\n",
    "val_dataset = change_dataset_np.ChangeDatasetNumpy(val_pickle_file, data_transforms['val'])\n",
    "image_datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "# Create training and validation dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "dataloaders_dict = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Tensorboard Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default directory \"runs\"\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anaconda3/lib/python3.7/site-packages/torch/onnx/symbolic.py:173: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    }
   ],
   "source": [
    "img_reference_dummy = torch.randn(1,3,img_size,img_size)\n",
    "img_test_dummy = torch.randn(1,3,img_size,img_size)\n",
    "change_net = models.ChangeNet(num_classes=num_classes)\n",
    "\n",
    "# Add on Tensorboard the Model Graph\n",
    "writer.add_graph(change_net, [img_reference_dummy, img_test_dummy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Model to GPUs (If Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_gpu > 1:\n",
    "    change_net = nn.DataParallel(change_net)\n",
    "change_net = change_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load('./best_model.pkl')\n",
    "#change_net.load_state_dict(checkpoint);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "# If there are more than 2 classes the alpha need to be a list\n",
    "criterion = losses.FocalLoss(gamma=2.0, alpha=0.25)\n",
    "optimizer = optim.Adam(change_net.parameters(), lr=base_lr)    \n",
    "sc_plt = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.0043\n",
      "val Loss: 0.0023\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0019\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0013\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0021\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0011\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0015\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0012\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0010\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0009\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0009\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0009\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0021\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0009\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0008\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0008\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0007\n",
      "Epoch 17/49\n",
      "----------\n",
      "val Loss: 0.0007\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0007\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0007\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0007\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0010\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0008\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0007\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0007\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0006\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0006\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "best_model, _ = utils_train.train_model(change_net, dataloaders_dict, criterion, optimizer, sc_plt, writer, device, num_epochs=num_epochs)\n",
    "torch.save(best_model.state_dict(), './best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx=widgets.IntSlider(min=0,max=len(val_dataset)-1))\n",
    "def explore_validation_dataset(idx):\n",
    "    best_model.eval()\n",
    "    sample = val_dataset[idx]\n",
    "    reference = sample['reference'].unsqueeze(0)\n",
    "    reference_img = sample['reference'].permute(1, 2, 0).cpu().numpy()\n",
    "    test_img = sample['test'].permute(1, 2, 0).cpu().numpy()\n",
    "    test = sample['test'].unsqueeze(0)\n",
    "    #label = sample['label'].type(torch.LongTensor).squeeze(0).cpu().numpy()\n",
    "    label = (sample['label']>0).type(torch.LongTensor).squeeze(0).cpu().numpy()\n",
    "    pred = best_model([reference, test])\n",
    "    #print(pred.shape)\n",
    "    _, output = torch.max(pred, 1)\n",
    "    output = output.squeeze(0).cpu().numpy()\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    fig.add_subplot(2, 2, 1)\n",
    "    plt.imshow(reference_img)\n",
    "    plt.title('Reference')\n",
    "    fig.add_subplot(2, 2, 2)\n",
    "    plt.imshow(test_img)\n",
    "    plt.title('Test')\n",
    "    fig.add_subplot(2, 2, 3)\n",
    "    plt.imshow(label)\n",
    "    plt.title('Label')\n",
    "    fig.add_subplot(2, 2, 4)\n",
    "    plt.imshow(output)\n",
    "    plt.title('ChangeNet Output')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
